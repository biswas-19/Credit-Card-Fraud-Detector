{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOH+HlyL+dKXx0LSHWH3cOh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MnQTclJQmPGU","executionInfo":{"status":"ok","timestamp":1737643726522,"user_tz":-330,"elapsed":344413,"user":{"displayName":"Biswas Sahu","userId":"17536287914026515981"}},"outputId":"d86c692d-f7eb-4db5-ebd7-154811f0981e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.8854 - val_loss: nan\n","Epoch 2/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7549 - val_loss: nan\n","Epoch 3/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.7095 - val_loss: nan\n","Epoch 4/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.7424 - val_loss: nan\n","Epoch 5/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7095 - val_loss: nan\n","Epoch 6/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.7158 - val_loss: nan\n","Epoch 7/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.7102 - val_loss: nan\n","Epoch 8/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7075 - val_loss: nan\n","Epoch 9/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.6994 - val_loss: nan\n","Epoch 10/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6843 - val_loss: nan\n","Epoch 11/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6918 - val_loss: nan\n","Epoch 12/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.7258 - val_loss: nan\n","Epoch 13/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6954 - val_loss: nan\n","Epoch 14/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7003 - val_loss: nan\n","Epoch 15/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.7201 - val_loss: nan\n","Epoch 16/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.6874 - val_loss: nan\n","Epoch 17/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: nan\n","Epoch 18/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.7177 - val_loss: nan\n","Epoch 19/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.7090 - val_loss: nan\n","Epoch 20/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.7180 - val_loss: nan\n","Epoch 21/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.7534 - val_loss: nan\n","Epoch 22/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6941 - val_loss: nan\n","Epoch 23/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.7435 - val_loss: nan\n","Epoch 24/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.7148 - val_loss: nan\n","Epoch 25/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.7054 - val_loss: nan\n","Epoch 26/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.6855 - val_loss: nan\n","Epoch 27/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.7025 - val_loss: nan\n","Epoch 28/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.7043 - val_loss: nan\n","Epoch 29/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6958 - val_loss: nan\n","Epoch 30/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7030 - val_loss: nan\n","Epoch 31/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7214 - val_loss: nan\n","Epoch 32/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.7030 - val_loss: nan\n","Epoch 33/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7061 - val_loss: nan\n","Epoch 34/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.7146 - val_loss: nan\n","Epoch 35/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.7152 - val_loss: nan\n","Epoch 36/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.7083 - val_loss: nan\n","Epoch 37/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.7092 - val_loss: nan\n","Epoch 38/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.6878 - val_loss: nan\n","Epoch 39/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.7316 - val_loss: nan\n","Epoch 40/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 0.6991 - val_loss: nan\n","Epoch 41/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6992 - val_loss: nan\n","Epoch 42/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.7138 - val_loss: nan\n","Epoch 43/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6981 - val_loss: nan\n","Epoch 44/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.7113 - val_loss: nan\n","Epoch 45/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.7002 - val_loss: nan\n","Epoch 46/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.7082 - val_loss: nan\n","Epoch 47/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6967 - val_loss: nan\n","Epoch 48/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7150 - val_loss: nan\n","Epoch 49/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.6895 - val_loss: nan\n","Epoch 50/50\n","\u001b[1m2776/2776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.7089 - val_loss: nan\n","\u001b[1m3469/3469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n","[   164    362    601 ... 110893 110968 110999]\n"]}],"source":["# Import the libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from keras.layers import Input, Dense\n","from keras.models import Model\n","\n","# Load the credit card transaction data\n","df = pd.read_csv(\"creditcard.csv\")\n","\n","# Extract the features from the data\n","X = df.iloc[:, :-1]\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Set the dimensions of the encoding layer\n","encoding_dim = 32\n","\n","# Define the input layer\n","input_layer = Input(shape=(X.shape[1],))\n","\n","# Define the encoding layer\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Define the decoding layer\n","decoded = Dense(X.shape[1], activation='sigmoid')(encoded)\n","\n","# Define the autoencoder model\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the autoencoder model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the autoencoder model\n","autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=32, shuffle=True, validation_split=0.2)\n","\n","# Use the autoencoder to reconstruct the input data\n","X_pred = autoencoder.predict(X_scaled)\n","\n","# Calculate the reconstruction error for each sample\n","reconstruction_error = np.mean(np.square(X_pred - X_scaled), axis=1)\n","\n","# Set a threshold for the reconstruction error\n","threshold = 5\n","\n","# Identify the transactions that have a reconstruction error above the threshold\n","fraud_index = np.where(reconstruction_error > threshold)[0]\n","\n","# Print the indices of the fraudulent transactions\n","print(fraud_index)"]}]}